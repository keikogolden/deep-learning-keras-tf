{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3775787c",
   "metadata": {},
   "source": [
    "This script will handle 4 in the ticket KE144.\n",
    "\n",
    "INSTRCUTION in KE144.\n",
    "\n",
    "- We should set up continuous QA for ontology stored in the SQL db that has the following steps:\n",
    "1. Checking for null skills and definitions in each locale (relative to the main skills table).\n",
    "\n",
    "2. Running language detection and monitoring for mismatches between locales and ML predictions.\n",
    "\n",
    "3. Identifying a character set for each locale and checking that no superfluous characters show up in each locale.\n",
    "\n",
    "4. Vectorizing titles and definitions and checking that similarity thresholds do not fall below a certain threshold.\n",
    "\n",
    "5. Checking for trailing and leading whitespace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc124b76",
   "metadata": {},
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92242140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'sql_functions' from 'C:\\\\Users\\\\KeikoGolden\\\\ComputationalLiguistics\\\\Annotaion\\\\bn_nb_s\\\\PythonTocheckModel\\\\PullRequests\\\\.\\\\sql_functions.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import importlib\n",
    "sys.path.insert(0, \".\")\n",
    "\n",
    "import sql_functions as sf\n",
    "from sql_functions import *\n",
    "importlib.reload(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7f0217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from psycopg2.extras import execute_values\n",
    "\n",
    "with open(\"config.yml\") as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c1b343",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "        database=config['db']['name'], \n",
    "        user=config['db']['user'], \n",
    "        host=config['db']['host'], \n",
    "        password=config['db']['password']\n",
    "    )\n",
    "\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab5549b",
   "metadata": {},
   "source": [
    "# 1. Create a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652fb36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KeikoGolden\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skill</th>\n",
       "      <th>skill_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.NET Assemblies</td>\n",
       "      <td>Defined by Microsoft for use in recent version...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.NET Reflector</td>\n",
       "      <td>.NET Reflector is a class browser, decompiler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.NET Remoting</td>\n",
       "      <td>.NET Remoting is a Microsoft application progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020 Design</td>\n",
       "      <td>2020 Design is a kitchen and bathroom design s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2D Gel Analysis Software</td>\n",
       "      <td>In quantitative proteomics, these tools primar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12638</th>\n",
       "      <td>Quarry Drilling</td>\n",
       "      <td>Drilling and blasting is the controlled use of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12639</th>\n",
       "      <td>Radio Direction</td>\n",
       "      <td>A radio direction finder is a device for findi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12640</th>\n",
       "      <td>Abrasive Blasting</td>\n",
       "      <td>Abrasive blasting, more commonly known as sand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12641</th>\n",
       "      <td>Heavy-metal Machine Operation</td>\n",
       "      <td>A heavy equipment operator operates heavy equi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12642</th>\n",
       "      <td>Command and Control System</td>\n",
       "      <td>Command and control is a \"set of organizationa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12643 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               skill  \\\n",
       "0                    .NET Assemblies   \n",
       "1                     .NET Reflector   \n",
       "2                      .NET Remoting   \n",
       "3                        2020 Design   \n",
       "4           2D Gel Analysis Software   \n",
       "...                              ...   \n",
       "12638                Quarry Drilling   \n",
       "12639                Radio Direction   \n",
       "12640              Abrasive Blasting   \n",
       "12641  Heavy-metal Machine Operation   \n",
       "12642     Command and Control System   \n",
       "\n",
       "                                        skill_definition  \n",
       "0      Defined by Microsoft for use in recent version...  \n",
       "1      .NET Reflector is a class browser, decompiler ...  \n",
       "2      .NET Remoting is a Microsoft application progr...  \n",
       "3      2020 Design is a kitchen and bathroom design s...  \n",
       "4      In quantitative proteomics, these tools primar...  \n",
       "...                                                  ...  \n",
       "12638  Drilling and blasting is the controlled use of...  \n",
       "12639  A radio direction finder is a device for findi...  \n",
       "12640  Abrasive blasting, more commonly known as sand...  \n",
       "12641  A heavy equipment operator operates heavy equi...  \n",
       "12642  Command and control is a \"set of organizationa...  \n",
       "\n",
       "[12643 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "command = \"\"\"select skill, skill_definition from skills_en_us\"\"\"\n",
    "df = pd.read_sql(command, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "499c3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a27c6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12517"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f94e6b",
   "metadata": {},
   "source": [
    "# 2. Using SkyHive vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927c407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "docs = list(nlp.pipe(df['skill'][:350].tolist())) #change list_of_all_skills to the list you have\n",
    "\n",
    "tokenized_sents = []\n",
    "for doc in docs: #doc is a skill\n",
    "    tokens = [i.text for i in doc]\n",
    "    tokenized_sents.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de642768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['.NET', 'Assemblies'],\n",
       " ['.NET', 'Reflector'],\n",
       " ['.NET', 'Remoting'],\n",
       " ['2020', 'Design'],\n",
       " ['2D', 'Gel', 'Analysis', 'Software'],\n",
       " ['Closed', '-', 'Loop', 'Medication'],\n",
       " ['35', 'Mm', 'Films'],\n",
       " ['3D', 'Camcorder'],\n",
       " ['3D', 'Programming'],\n",
       " ['3D', 'Recognition', 'Systems'],\n",
       " ['3D', 'Reconstruction'],\n",
       " ['Global', 'Command', 'And', 'Control', 'Systems'],\n",
       " ['3D', 'Graphics'],\n",
       " ['3D', 'Modelling'],\n",
       " ['.NET', 'Core'],\n",
       " ['.NET', 'Framework'],\n",
       " ['3D'],\n",
       " ['360', 'Degree', 'Thinking'],\n",
       " ['3D', 'Design'],\n",
       " ['3D', 'Printing'],\n",
       " ['2D', 'Animation'],\n",
       " ['2D', 'Motion', 'Graphic'],\n",
       " ['3D', 'Motion', 'Graphic'],\n",
       " ['2D', 'Printing'],\n",
       " ['3D', 'Analyst', 'Extension'],\n",
       " ['Twelve', '-', 'Factor', 'App'],\n",
       " ['Category', '2', 'Cable'],\n",
       " ['Granim.js'],\n",
       " ['3D', 'scene', '-', 'graph', 'architecture'],\n",
       " ['3D', 'Seismic', 'Interpretation'],\n",
       " ['510(k', ')'],\n",
       " ['529', 'College', 'Savings', 'Planning'],\n",
       " ['Ab', 'Initio', 'Algorithm'],\n",
       " ['Cluster', 'Management'],\n",
       " ['Firebird', 'Database'],\n",
       " ['A', '/', 'B', 'testing'],\n",
       " ['Abaqus'],\n",
       " ['Abc', 'Analysis'],\n",
       " ['Abdominal', 'Ultrasonography'],\n",
       " ['ABI', 'Solid', 'Sequencing'],\n",
       " ['Ableton', 'Live'],\n",
       " ['Above', 'Water', 'Warfare', 'System'],\n",
       " ['ABR', 'Routers'],\n",
       " ['AB&C', 'Policy'],\n",
       " ['3D', 'Visualization'],\n",
       " ['Abb', 'Robotics', 'Programming'],\n",
       " ['Abnormal', 'Psychology'],\n",
       " ['5', 'G'],\n",
       " ['A+', 'Certification'],\n",
       " ['5S', 'Methodology'],\n",
       " ['Abdominal', 'Trauma'],\n",
       " ['Assessment', 'and', 'Authorization', '(', 'A&A', ')'],\n",
       " ['Assessment',\n",
       "  'and',\n",
       "  'Authorization',\n",
       "  'Risk',\n",
       "  'Management',\n",
       "  'Framework',\n",
       "  '(',\n",
       "  'A&A',\n",
       "  'RMF',\n",
       "  ')'],\n",
       " ['Category', '5', 'Cable'],\n",
       " ['Abscesses'],\n",
       " ['Absolute', 'Manage'],\n",
       " ['Abstract', 'Management'],\n",
       " ['Abstract', 'Syntax', 'Notation', 'One'],\n",
       " ['Abutments'],\n",
       " ['Academic', 'Advising'],\n",
       " ['Acceptance', 'Sampling'],\n",
       " ['Integrated', 'Maintenance', 'Data', 'System'],\n",
       " ['Account', 'Aggregation'],\n",
       " ['Acupuncture'],\n",
       " ['Abstract', 'Algebra'],\n",
       " ['Account', 'Analysis'],\n",
       " ['Accelerated', 'Failure', 'Time', 'Models'],\n",
       " ['Access', 'Control', 'System'],\n",
       " ['Access', 'Management'],\n",
       " ['Acceptance', 'Testing'],\n",
       " ['Abstract', 'Window', 'Toolkit'],\n",
       " ['ACA', 'Instructor', 'Certificate'],\n",
       " ['Accordion'],\n",
       " ['CDL', 'Class', 'B'],\n",
       " ['Access', '&', 'Authentication'],\n",
       " ['Accident', 'Reporting'],\n",
       " ['AC', '/', 'DC', 'Power'],\n",
       " ['Advisory',\n",
       "  ',',\n",
       "  'Conciliation',\n",
       "  'and',\n",
       "  'Arbitration',\n",
       "  'Service',\n",
       "  '(',\n",
       "  'ACAS',\n",
       "  ')'],\n",
       " ['Account', 'Reconciliation'],\n",
       " ['Cloud', 'Analytics'],\n",
       " ['Account', '-', 'based', 'Marketing'],\n",
       " ['Accounting', 'System', 'Design'],\n",
       " ['Accredited', 'Adviser', 'In', 'Insurance'],\n",
       " ['Accredited', 'Domestic', 'Partnership', 'Advisor'],\n",
       " ['Accrual', 'Accounting'],\n",
       " ['Certified', 'Loss', 'Control', 'Specialist'],\n",
       " ['Acoustic', 'Data', 'Analysis'],\n",
       " ['ACI', 'Concrete', 'Field', 'Testing', 'Technician'],\n",
       " ['ACI', 'Concrete', 'Laboratory', 'Testing', 'Technician'],\n",
       " ['ACI', 'Concrete', 'Strength', 'Testing', 'Technician'],\n",
       " ['Acoustic', 'Guitar'],\n",
       " ['Accounts', 'Payable'],\n",
       " ['Accounts', 'Payable', 'Workflow'],\n",
       " ['Accounts', 'Receivable'],\n",
       " ['Acoustic', 'Doppler', 'Current', 'Profiler'],\n",
       " ['Accounting'],\n",
       " ['Accounting', 'Concept'],\n",
       " ['Accounting', 'Control'],\n",
       " ['ACID', 'Pro'],\n",
       " ['Accounting', 'Cycle'],\n",
       " ['Acid', 'Hydrolysis'],\n",
       " ['Accredited', 'Investment', 'Fiduciary'],\n",
       " ['Acoustic', 'Scattering'],\n",
       " ['Acoustic', 'Suspension'],\n",
       " ['Acoustical', 'Intelligence'],\n",
       " ['IBM', 'Sametime'],\n",
       " ['Acronis', 'True', 'Image'],\n",
       " ['Active', 'Directory', 'Federation', 'Services'],\n",
       " ['Active', 'Hdl'],\n",
       " ['HP', 'Asset', 'Manager'],\n",
       " ['IBM', 'Quickr'],\n",
       " ['Actuarial', 'Assumption'],\n",
       " ['Actuarial', 'Exams'],\n",
       " ['Actuarial', 'Science'],\n",
       " ['Actuarial', 'Software'],\n",
       " ['Acumatica'],\n",
       " ['Acupressure'],\n",
       " ['Acquisition', 'Strategy'],\n",
       " ['Acting'],\n",
       " ['Acoustic', 'Sensor'],\n",
       " ['Action', 'Resolution'],\n",
       " ['Acoustic', 'Propagation'],\n",
       " ['Acoustical', 'Engineering'],\n",
       " ['Acoustic', 'Training'],\n",
       " ['Acoustic', 'Range', 'Prediction'],\n",
       " ['ActivePivot'],\n",
       " ['Act', '!', 'CRM'],\n",
       " ['Acquisition', 'Life', 'Cycle', 'Framework'],\n",
       " ['Acoustic', 'Weapons', 'Locating', 'System'],\n",
       " ['Acute', 'Renal', 'Failure'],\n",
       " ['Ad', 'Hoc', 'Testing'],\n",
       " ['Ad', 'Valorem', 'Tax'],\n",
       " ['Ada', 'Compliance'],\n",
       " ['Adaptive', 'Neuro', 'Fuzzy', 'Inference', 'Systems'],\n",
       " ['Clustering', 'Software'],\n",
       " ['Adept', 'Software', 'Suite'],\n",
       " ['Adhoc', 'Queries'],\n",
       " ['Adjacency', 'Matrix'],\n",
       " ['Ad', 'Operation'],\n",
       " ['Adjusted', 'Gross', 'Income'],\n",
       " ['Adaptability'],\n",
       " ['Acute', 'Care'],\n",
       " ['Adapter', 'Scripting', 'Language'],\n",
       " ['Adaptation', 'Kit', 'Upgrade'],\n",
       " ['Acute', 'Assessment', 'Unit'],\n",
       " ['Addressing', 'Ethical', 'Concerns'],\n",
       " ['Acute', 'Care', 'Management'],\n",
       " ['Acute', 'Pain', 'Management'],\n",
       " ['Address', 'Resolution', 'Protocols'],\n",
       " ['Adipose', 'Tissue'],\n",
       " ['Advanced', 'Driver', '-', 'Assistance', 'Systems', '(', 'ADAS', ')'],\n",
       " ['Luxembourgish', 'Language'],\n",
       " ['Administer', 'Vaccinations'],\n",
       " ['Administering',\n",
       "  'Cisco',\n",
       "  'Unified',\n",
       "  'Communications',\n",
       "  'Manager',\n",
       "  'And',\n",
       "  'Unity',\n",
       "  'Connection'],\n",
       " ['Central', 'Sterilization', 'Process'],\n",
       " ['Adobe', 'Animate'],\n",
       " ['Admixtures'],\n",
       " ['ADO.NET'],\n",
       " ['ADO.NET', 'Data', 'Services'],\n",
       " ['Adobe', 'Acrobat'],\n",
       " ['Adobe', 'After', 'Effects'],\n",
       " ['Adobe', 'AIR'],\n",
       " ['Adobe', 'Audition'],\n",
       " ['Adobe', 'Bridge'],\n",
       " ['Adobe', 'Captivate'],\n",
       " ['Adobe', 'ColdFusion'],\n",
       " ['Cgi', 'Application'],\n",
       " ['Administrative', 'Support'],\n",
       " ['Adjustment', 'Computation'],\n",
       " ['Adobe', 'Analytics'],\n",
       " ['Adobe', 'Creative', 'Suite'],\n",
       " ['Adobe', 'Acrobat', 'DC'],\n",
       " ['Administrative', 'Coordination'],\n",
       " ['Adobe', 'Director'],\n",
       " ['Adobe', 'Encore'],\n",
       " ['Adobe', 'Experience', 'Manager'],\n",
       " ['Adobe', 'Fireworks'],\n",
       " ['Adobe', 'Flash'],\n",
       " ['Adobe', 'Flash', 'Lite'],\n",
       " ['Adobe', 'Flash', 'Professional'],\n",
       " ['Adobe', 'Font', 'Folio'],\n",
       " ['Adobe', 'Illustrator'],\n",
       " ['Adobe', 'Presenter'],\n",
       " ['Adobe', 'Story'],\n",
       " ['Adobe', 'Edge', 'Animate'],\n",
       " ['Adobe', 'Version', 'Cue'],\n",
       " ['Adobe', 'XD'],\n",
       " ['Adolescent', 'Health'],\n",
       " ['ADP', 'Enterprise'],\n",
       " ['ADP', 'Reporting'],\n",
       " ['ADP', 'Vantage'],\n",
       " ['Adobe', 'InDesign'],\n",
       " ['Adobe', 'Lightroom'],\n",
       " ['Adobe', 'PageMaker'],\n",
       " ['ADP', 'Payroll', 'Solutions'],\n",
       " ['Adobe', 'Photoshop'],\n",
       " ['Adobe', 'Photoshop', 'Album'],\n",
       " ['Aircraft', 'Piloting'],\n",
       " ['SAP', 'Business', 'Software'],\n",
       " ['ADP', 'Workforce', 'Now'],\n",
       " ['ADT', 'Security', 'Services'],\n",
       " ['Advance', 'Design', 'System'],\n",
       " ['Advance', 'Ship', 'Notice'],\n",
       " ['Advanced', 'Combat', 'Direction', 'Systems'],\n",
       " ['Advanced', 'Message', 'Queuing', 'Protocol'],\n",
       " ['Advanced', 'Metering', 'Infrastructure'],\n",
       " ['Advanced', 'Engineering'],\n",
       " ['Advanced', 'Health', 'Management', 'Systems'],\n",
       " ['Advanced', 'Java'],\n",
       " ['Macspeech'],\n",
       " ['Advanced', 'SCSI', 'Programming', 'Interface'],\n",
       " ['Advanced', 'Calculus'],\n",
       " ['Advanced', 'English'],\n",
       " ['Advanced', 'Auditing'],\n",
       " ['Advanced', 'Accounting'],\n",
       " ['Advanced', 'Access', 'Content', 'Systems'],\n",
       " ['Advanced', 'Microcontroller', 'Bus', 'Architecture'],\n",
       " ['Advanced', 'Microprocessor'],\n",
       " ['Adult', 'Education'],\n",
       " ['Advanced', 'Host', 'Controller', 'Interface'],\n",
       " ['Advanced', 'Process', 'Control'],\n",
       " ['Advanced', 'Certified', 'Hospice', 'And', 'Palliative', 'Nurse'],\n",
       " ['Change', 'Management'],\n",
       " ['Land', 'Surveying'],\n",
       " ['Advanced', 'Technical', 'Information', 'System'],\n",
       " ['Adverse', 'Event', 'Report'],\n",
       " ['Adverse', 'Media', 'Checking'],\n",
       " ['Aeration'],\n",
       " ['Aerial', 'Imagery'],\n",
       " ['Aeronautical', 'Message', 'Handling', 'Systems'],\n",
       " ['Aerobic', 'Organisms'],\n",
       " ['Motor', 'Vehicles'],\n",
       " ['Aerodynamics'],\n",
       " ['Aerodynamics', 'Engineering'],\n",
       " ['Aeronautics'],\n",
       " ['Aerospace', 'Design'],\n",
       " ['Aerospace', 'Medicine'],\n",
       " ['Aerospike'],\n",
       " ['Aerostructure'],\n",
       " ['AES', 'Network', 'Systems'],\n",
       " ['AML', 'Legal', '&', 'Regulatory', 'Knowledge'],\n",
       " ['Aerospace', 'Vehicle', 'Development'],\n",
       " ['Aerospace', 'Precision', 'Welding'],\n",
       " ['Aegis', 'Ballistic', 'Missile', 'Defense', 'Systems'],\n",
       " ['Advanced', 'Volatile', 'Threat'],\n",
       " ['Advanced', 'Search', 'Advertising'],\n",
       " ['Advertising'],\n",
       " ['Aerial', 'Lift', 'Operation'],\n",
       " ['Aesthetics'],\n",
       " ['AFC', 'Customer', 'Management'],\n",
       " ['AFC', 'Risk'],\n",
       " ['Affidavit', 'Preparation'],\n",
       " ['Affinity', 'Marketing'],\n",
       " ['Affirmative', 'Defense'],\n",
       " ['AFIS'],\n",
       " ['Aftersales'],\n",
       " ['Agarose', 'Gel', 'Electrophoresis'],\n",
       " ['Agent', 'Extensibility', 'Protocols'],\n",
       " ['AGFA', 'Impax', '6'],\n",
       " ['AggFlow'],\n",
       " ['Agglutination'],\n",
       " ['Aggregate', 'Gradation'],\n",
       " ['Aggregate', 'Planning'],\n",
       " ['Aggregation', 'Analysis'],\n",
       " ['Aggression', 'Replacement', 'Training'],\n",
       " ['AGi32'],\n",
       " ['Aggregate', 'Safety', 'Report'],\n",
       " ['Aggregate', 'Functions'],\n",
       " ['Affiliate', 'Marketing'],\n",
       " ['AFC', 'Escalations'],\n",
       " ['Digital', 'Guardian', 'Software'],\n",
       " ['Proofpoint', 'Software'],\n",
       " ['Agile', 'Central'],\n",
       " ['Agile', 'Modeling'],\n",
       " ['Agile', 'Teaming'],\n",
       " ['Agribusiness'],\n",
       " ['Agronomic', 'Practice'],\n",
       " ['Agronomy'],\n",
       " ['Ahrefs', 'Site', 'Explorer'],\n",
       " ['AI', 'Interaction'],\n",
       " ['Agricultural', 'Machinery'],\n",
       " ['Air', 'Brakes'],\n",
       " ['Agile', 'Management'],\n",
       " ['Agile', 'Metrics'],\n",
       " ['Agricultural', 'Economics'],\n",
       " ['Agriculture'],\n",
       " ['Agile', 'Coaching'],\n",
       " ['Agricultural', 'Microbiology'],\n",
       " ['Agile', 'Practices'],\n",
       " ['Agility'],\n",
       " ['Agility', 'CMS'],\n",
       " ['Agricultural', 'Engineering'],\n",
       " ['AI', 'Platform'],\n",
       " ['Agricultural', 'Science'],\n",
       " ['Agricultural', 'Testing'],\n",
       " ['Forcepoint', 'DLP', 'Software'],\n",
       " ['Netskope', 'Security', 'Service', 'Edge'],\n",
       " ['Boldon', 'James', 'Classifier'],\n",
       " ['Air', 'Carbon', 'Arc'],\n",
       " ['Air', 'Conditioner', 'Repair'],\n",
       " ['Air', 'Refueling'],\n",
       " ['Air', 'Sampling'],\n",
       " ['Air', 'Track', 'Drilling'],\n",
       " ['Air', 'Traffic', 'Control'],\n",
       " ['Aircraft', 'Mechanical', 'Systems', 'Inspection'],\n",
       " ['Aircraft', 'Balance', 'Evaluation'],\n",
       " ['Aircraft', 'Control'],\n",
       " ['APL', '(', 'Programming', 'Language', ')'],\n",
       " ['Aircraft', 'Engine', 'Assembly'],\n",
       " ['Aircraft', 'Hydraulic', 'Components'],\n",
       " ['Aircraft', 'Hydraulics', 'Repair'],\n",
       " ['Aircraft', 'Mechanical', 'Systems', 'Maintenance'],\n",
       " ['Aircraft', 'Design'],\n",
       " ['Aircraft', 'Materials'],\n",
       " ['Airborne', 'Electronic', 'Sensor'],\n",
       " ['Aircraft', 'Operation'],\n",
       " ['Aircraft', 'Engine', 'Repair'],\n",
       " ['Air', 'Pollution', 'Control'],\n",
       " ['Air', 'Mobility', 'Operation'],\n",
       " ['Air', 'Monitoring'],\n",
       " ['Airbrush', 'Makeup'],\n",
       " ['Change', 'Planning'],\n",
       " ['Aircraft', 'Inspection'],\n",
       " ['Administering', 'Medicine'],\n",
       " ['Restoration', '(', 'Sculpture', ')'],\n",
       " ['Alkaline', 'Lysis'],\n",
       " ['Aircraft', 'Systems', 'Monitoring'],\n",
       " ['Aircraft', 'Wheel', 'and', 'Brake'],\n",
       " ['Airport', 'Movement', 'Area', 'Safety', 'Systems'],\n",
       " ['Airspace', 'Control', 'Measures'],\n",
       " ['Airworthiness', 'Policy'],\n",
       " ['AISC', '360', 'Specification', 'For', 'Structural', 'Steel', 'Buildings'],\n",
       " ['Akamai'],\n",
       " ['Alchemy', 'Catalyst'],\n",
       " ['Alfresco', 'ECM'],\n",
       " ['Algae', 'Identification'],\n",
       " ['Alkylation', 'Units'],\n",
       " ['All', 'India', 'Senior', 'School', 'Certificate', 'Examination'],\n",
       " ['Aliasing'],\n",
       " ['Akka'],\n",
       " ['AML', 'Legal', 'and', 'Regulatory'],\n",
       " ['ALA', 'Lighting', 'Specialist', 'Certification'],\n",
       " ['Algebra'],\n",
       " ['Airplane', 'Cabin', 'Safety'],\n",
       " ['Algorithms'],\n",
       " ['Airline', 'Transport', 'Pilot', 'Licence'],\n",
       " ['Akka.net'],\n",
       " ['Algorithm', 'Development'],\n",
       " ['Restoration', '(', 'Artifact', ')'],\n",
       " ['All', '-', 'source', 'Collection', 'Operations']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aca2961",
   "metadata": {},
   "source": [
    "##### Option 1: Vectorize small batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7991aac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "region = \"ca-central-1\"\n",
    "vectorizer_name = \"vectorizer-cpu-2\"\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region)\n",
    "\n",
    "def vectorize_remote(\n",
    "        sents: List[List[str]],\n",
    "        offsets: List[List[List[int]]]) -> List[List[List[float]]]:\n",
    "    data = {\"sents\": sents, \"offsets\": offsets}\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=vectorizer_name,\n",
    "        Body=bytes(json.dumps(data), encoding=\"utf-8\"),\n",
    "        ContentType='application/json'\n",
    "\n",
    "    )\n",
    "    output = response['Body'].read().decode('utf-8')\n",
    "    output = json.loads(json.loads(output)[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866833a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 5]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 5]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 6]],\n",
       " [[0, 10]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 9]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 5]],\n",
       " [[0, 5]],\n",
       " [[0, 5]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 5]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 8]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 8]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 6]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 5]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 5]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 5]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 2]],\n",
       " [[0, 3]],\n",
       " [[0, 4]],\n",
       " [[0, 5]],\n",
       " [[0, 3]],\n",
       " [[0, 2]],\n",
       " [[0, 7]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 2]],\n",
       " [[0, 6]],\n",
       " [[0, 1]],\n",
       " [[0, 1]],\n",
       " [[0, 4]],\n",
       " [[0, 4]],\n",
       " [[0, 1]],\n",
       " [[0, 3]],\n",
       " [[0, 1]],\n",
       " [[0, 4]],\n",
       " [[0, 1]],\n",
       " [[0, 2]],\n",
       " [[0, 4]],\n",
       " [[0, 5]]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offsets = [[[0, len(sent)]] for sent in tokenized_sents]\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeb67c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(offsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbf70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorize_remote(\n",
    "    tokenized_sents,\n",
    "    offsets\n",
    ")\n",
    "\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d28252",
   "metadata": {},
   "source": [
    "##### Option2 Concurrent vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6561b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets_df = pd.DataFrame({'offsets': offsets})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47ccf36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents_df = pd.DataFrame({'tokenized_sents': tokenized_sents})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843517ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "region = \"ca-central-1\"\n",
    "vectorizer_name = \"vectorizer-cpu-2\"\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efd51bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent\n",
    "import multiprocessing as mp\n",
    "\n",
    "def concurrent_vectorization(\n",
    "            sent_chunks: List[List[List[str]]],\n",
    "            offset_chunks: List[List[List[List[int]]]]\n",
    "    ) -> List[List[List[List[float]]]]:\n",
    "        \"\"\"Concurrency wrapper for self.vectorize\"\"\"\n",
    "        results = []\n",
    "        with concurrent.futures.ThreadPoolExecutor(\n",
    "                max_workers=mp.cpu_count() * 2) as executor:\n",
    "            for result in executor.map(vectorize(sent_chunks, offset_chunks), sent_chunks, offset_chunks):\n",
    "                results.extend(result)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27d738b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(sents: List[List[str]],\n",
    "                  offsets: List[List[List[int]]]) -> List[List[List[float]]]:\n",
    "        data = {\"sents\": sents, \"offsets\": offsets}\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=vectorizer_name,\n",
    "            Body=bytes(json.dumps(data), encoding=\"utf-8\"),\n",
    "            ContentType='application/json'\n",
    "\n",
    "        )\n",
    "        output = response['Body'].read().decode('utf-8')\n",
    "        output = json.loads(json.loads(output)[0])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8865c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorization\n",
    "        tokenized_sents = list(df.token)\n",
    "        tokenized_batches = [tokenized_sents[i:i + self.chunk_size] for i\n",
    "                             in range(0, len(tokenized_sents), self.chunk_size)]\n",
    "        offsets = list(df.combined_spans_shifted)\n",
    "        offset_batches = [offsets[i:i + self.chunk_size] for i in\n",
    "                          range(0, len(offsets), self.chunk_size)]\n",
    "        vectors = self.concurrent_vectorization(tokenized_batches,\n",
    "                                                offset_batches)\n",
    "        df['vector'] = vectors\n",
    "        vector_batches = [vectors[i:i + self.chunk_size] for i in range(0,\n",
    "                          len(vectors), self.chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d77c01",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModelError",
     "evalue": "An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\"\n}\n\". See https://ca-central-1.console.aws.amazon.com/cloudwatch/home?region=ca-central-1#logEventViewer:group=/aws/sagemaker/Endpoints/vectorizer-cpu-2 in account 596298976885 for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModelError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m offsets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(offsets_df\u001b[38;5;241m.\u001b[39moffsets)\n\u001b[0;32m      4\u001b[0m offset_batches \u001b[38;5;241m=\u001b[39m [offsets[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m50\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(offsets), \u001b[38;5;241m50\u001b[39m)]\n\u001b[1;32m----> 5\u001b[0m vectors \u001b[38;5;241m=\u001b[39m \u001b[43mconcurrent_vectorization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenized_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_batches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m vectors\n\u001b[0;32m      7\u001b[0m vector_batches \u001b[38;5;241m=\u001b[39m [vectors[i:i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m50\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vectors), \u001b[38;5;241m50\u001b[39m)]\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mconcurrent_vectorization\u001b[1;34m(sent_chunks, offset_chunks)\u001b[0m\n\u001b[0;32m      9\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor(\n\u001b[0;32m     11\u001b[0m         max_workers\u001b[38;5;241m=\u001b[39mmp\u001b[38;5;241m.\u001b[39mcpu_count() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m executor\u001b[38;5;241m.\u001b[39mmap(\u001b[43mvectorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset_chunks\u001b[49m\u001b[43m)\u001b[49m, sent_chunks, offset_chunks):\n\u001b[0;32m     13\u001b[0m         results\u001b[38;5;241m.\u001b[39mextend(result)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mvectorize\u001b[1;34m(sents, offsets)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvectorize\u001b[39m(sents: List[List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m      2\u001b[0m                   offsets: List[List[List[\u001b[38;5;28mint\u001b[39m]]]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[List[List[\u001b[38;5;28mfloat\u001b[39m]]]:\n\u001b[0;32m      3\u001b[0m         data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msents\u001b[39m\u001b[38;5;124m\"\u001b[39m: sents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffsets\u001b[39m\u001b[38;5;124m\"\u001b[39m: offsets}\n\u001b[1;32m----> 4\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43msagemaker_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mEndpointName\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectorizer_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mContentType\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mapplication/json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         output \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBody\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m         output \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(json\u001b[38;5;241m.\u001b[39mloads(output)[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py:401\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m py_operation_name)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\botocore\\client.py:731\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[1;34m(self, operation_name, api_params)\u001b[0m\n\u001b[0;32m    729\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m parsed_response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    730\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[1;32m--> 731\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[1;31mModelError\u001b[0m: An error occurred (ModelError) when calling the InvokeEndpoint operation: Received client error (400) from primary with message \"{\n  \"code\": 400,\n  \"type\": \"InternalServerException\",\n  \"message\": \"text input must of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).\"\n}\n\". See https://ca-central-1.console.aws.amazon.com/cloudwatch/home?region=ca-central-1#logEventViewer:group=/aws/sagemaker/Endpoints/vectorizer-cpu-2 in account 596298976885 for more information."
     ]
    }
   ],
   "source": [
    "tokenized_sents = list(tokenized_sents_df.tokenized_sents)\n",
    "tokenized_batches = [tokenized_sents[i:i + 50] for i in range(0, len(tokenized_sents), 50)]\n",
    "offsets = list(offsets_df.offsets)\n",
    "offset_batches = [offsets[i:i + 50] for i in range(0, len(offsets), 50)]\n",
    "vectors = concurrent_vectorization(tokenized_batches, offset_batches)\n",
    "df['vector'] = vectors\n",
    "vector_batches = [vectors[i:i + 50] for i in range(0, len(vectors), 50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "offset_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dbee12",
   "metadata": {},
   "source": [
    "# 3. Using Transformer vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3915055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5e0b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_skill = model.encode(df.skill.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc4528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_skill.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04374b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before vectorizing the definition, remove stop words and punctuation from it, so that embedding is fast and that you can make\n",
    "# a strong vectorising.\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    no_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    return \" \".join(no_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Above function call to create a list of preprocessed definitions.\n",
    "preprocessed_definition = []\n",
    "for definition in df.skill_definition.tolist():\n",
    "    results = preprocess(definition)\n",
    "    preprocessed_definition.append(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9be4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_definition[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97702a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_definition = model.encode(preprocessed_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7614f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_definition.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59bb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_definition[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4532ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "minor_title = []\n",
    "normlised_title = []\n",
    "sim_score = []\n",
    "\n",
    "for i, job_title in enumerate(sentence_embeddings_job_title):\n",
    "    for j, title in enumerate(sentence_embeddings_minor_job_title):\n",
    "        score = cosine_similarity([job_title],[title])\n",
    "        if score > 0.80:\n",
    "            minor_title.append(df.final_title_post_processed.iloc[j])\n",
    "            normlised_title.append(df4.Column1.iloc[i])\n",
    "            sim_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded6a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_df = pd.DataFrame({'skill_vector': sentence_embeddings_skill.tolist(), 'def_vector':sentence_embeddings_definition.tolist()})\n",
    "vectorized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746210d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim_score = []\n",
    "for i, row in vectorized_df.iterrows():\n",
    "    score = cosine_similarity(np.array(row[0]).reshape(1,-1), np.array(row[1]).reshape(1,-1))\n",
    "    sim_score.append(score[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e211122",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_score[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6856917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sim_score'] = sim_score\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('title_vs_def_similarity.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3d3108",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
