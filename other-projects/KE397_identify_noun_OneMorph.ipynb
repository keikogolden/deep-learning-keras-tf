{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81162e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c76d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel(\"C:/Users/KeikoGolden/ComputationalLiguistics/KE397_1500skillsCandidate/SnapshotAugust8/anay.xlsx\")\n",
    "df2 = pd.read_excel(\"C:/Users/KeikoGolden/ComputationalLiguistics/KE397_1500skillsCandidate/SnapshotAugust8/cassady.xlsx\")\n",
    "df3 = pd.read_excel(\"C:/Users/KeikoGolden/ComputationalLiguistics/KE397_1500skillsCandidate/SnapshotAugust8/desiree.xlsx\")\n",
    "df4 = pd.read_excel(\"C:/Users/KeikoGolden/ComputationalLiguistics/KE397_1500skillsCandidate/SnapshotAugust8/ethan.xlsx\")\n",
    "df5 = pd.read_excel(\"C:/Users/KeikoGolden/ComputationalLiguistics/KE397_1500skillsCandidate/SnapshotAugust8/syed.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([df1, df2, df3, df4, df5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bdb52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c1e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bff992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "lemmas = []\n",
    "for skill in all_df.skill_title.tolist()[:1000]:\n",
    "    doc = nlp(skill)\n",
    "    if len(doc)== 1:                               #Find unigram\n",
    "        for token in doc:                          \n",
    "            if token.pos_ == \"NOUN\":               #Find noun\n",
    "                print(skill + \": \" + \"NOUN\" + \"   Lemma: \" + token.lemma_)\n",
    "                #lemmas.append(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da166734",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1babc347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Polyglot\n",
      "  Using cached polyglot-16.7.4.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [8 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\KeikoGolden\\AppData\\Local\\Temp\\pip-install-zsbr_hxn\\polyglot_9991f23bf89a4028a9973a7f290d9321\\setup.py\", line 15, in <module>\n",
      "      readme = readme_file.read()\n",
      "    File \"C:\\Users\\KeikoGolden\\anaconda3\\lib\\encodings\\cp1252.py\", line 23, in decode\n",
      "      return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "  UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 4941: character maps to <undefined>\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install Polyglot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bbe953f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pysld2 (from versions: none)\n",
      "ERROR: No matching distribution found for pysld2\n"
     ]
    }
   ],
   "source": [
    "pip install pysld2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59e30b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: morfessor in c:\\users\\keikogolden\\anaconda3\\lib\\site-packages (2.0.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install morfessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec2b06b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'polyglot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpolyglot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m downloader\n\u001b[0;32m      2\u001b[0m downloader\u001b[38;5;241m.\u001b[39mdownload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmorph2.en\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'polyglot'"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.download(\"morph2.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542022cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "polyglot download ner2.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f7bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19a3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb330ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for lemma in lemmas:\n",
    "    print(lemma, '|', stemmer.stem(lemma))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62276204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#make sure wordnet is downloaded\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa03e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inflectional forms of a lemma using WordNet.\n",
    "# lemma (str): The word for which to get inflectional form.\n",
    "# pos (str, optional): part of speech ('n' for noun, 'v' for verb). If not specificed, all pos will be considered\n",
    "# Returns: list of inflectional forms in the given lemma\n",
    "\n",
    "def get_inflectional_forms(lemma, pos=pos):\n",
    "    \n",
    "    inflected_forms = []\n",
    "     \n",
    "    # Get synsets for the lemma\n",
    "    synsets = wordnet.synsets(lemma, pos = pos)\n",
    "    \n",
    "    for syn in synsets:\n",
    "        for lemma in syn.lemmas():\n",
    "            for form in lemma.frame_strings():\n",
    "                inflected_forms.append(form)\n",
    "                \n",
    "    return list(set(inflected_forms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885b334",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma = 'use'\n",
    "inflections = get_inflectional_forms(lemma, pos=\"v\")\n",
    "print(inflections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9223a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3601e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_multiple_inflections(word):\n",
    "    \n",
    "    #Find the lemma using morphy (this might not be perfect for all words)\n",
    "    # if morphy can't find a lemma, just use the original word\n",
    "    lemma = wordnet.morphy(word)\n",
    "    if not lemma:\n",
    "        lemma = word\n",
    "        \n",
    "    #Count inflectional forms\n",
    "    count = 0\n",
    "    for synset in wordnet.synsets(lemma):\n",
    "        for lemma in synset.lemmas():\n",
    "            if lemma.name() == lemma.name():\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfd81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = \"keep\"\n",
    "how_many = has_multiple_inflections(word)\n",
    "how_many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a606aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10cf86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
