{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf263a60",
   "metadata": {},
   "source": [
    "このスクリプトは、\"C:\\Users\\KeikoGolden\\TokyoOffice\\SkillDictionary\\Python\\FurtherFilter\\ skill_normalization_expanded_Copy.ipynb\"　から拡張したもの。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d37d12",
   "metadata": {},
   "source": [
    "1. Noamalize using skill_normalization.py\n",
    "2. Option 2 - Igonore This Section\n",
    "3. 02/29/2023 - Ignore This Section\n",
    "4. 02/09/2023 - No2 Spacy\n",
    "5. 02/11/2023 - SkyHive vectorizer\n",
    "6. 02/11/2023 - No2 Difflib\n",
    "7. 02/11/2023 Transformer Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23649547",
   "metadata": {},
   "source": [
    "# Normalize using skill_normalization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3821393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f6b6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_v3(skill_list, k=5):\n",
    "    response = requests.post(\n",
    "    url = 'https://testazure-ml-api.skyhive.io/job-title-normalization/titles_v3',\n",
    "    json = {\"titles\": skill_list, \"k\": k}\n",
    ")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41413ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def main_v3(skills: List[str]):\n",
    "    responses = []\n",
    "\n",
    "    for skill in tqdm(skills):\n",
    "        try:\n",
    "            response = normalize_v3([skill])\n",
    "        except:\n",
    "            response = None\n",
    "        responses.append(response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de48046a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users\\KeikoGolden/ComputationalLiguistics/Annotaion/bn_nb_s/PythonTocheckModel/soc_cleanup.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0947a544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>major</th>\n",
       "      <th>minor</th>\n",
       "      <th>detailed</th>\n",
       "      <th>major_title</th>\n",
       "      <th>minor_title</th>\n",
       "      <th>occupation_title_working</th>\n",
       "      <th>final_title_post_processed</th>\n",
       "      <th>definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11-0000</td>\n",
       "      <td>11-1000</td>\n",
       "      <td>11-1011</td>\n",
       "      <td>Management Occupations</td>\n",
       "      <td>Top Executives</td>\n",
       "      <td>Chief Executives</td>\n",
       "      <td>chief executive</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     major    minor detailed             major_title     minor_title  \\\n",
       "0  11-0000  11-1000  11-1011  Management Occupations  Top Executives   \n",
       "\n",
       "  occupation_title_working final_title_post_processed definition  \n",
       "0         Chief Executives            chief executive        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(file_path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c2e4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         chief executive\n",
       "1                                         general manager\n",
       "2                                      operations manager\n",
       "3                                              legislator\n",
       "4                                     advertising manager\n",
       "                              ...                        \n",
       "1453    lathe and turning machine tool setters, operat...\n",
       "1454    metal and plastic lathe and turning machine to...\n",
       "1455    metal and plastic lathe and turning machine to...\n",
       "1456    metal and plastic lathe and turning machine to...\n",
       "1457    lathe and turning machine tool setters, operat...\n",
       "Name: final_title_post_processed, Length: 1458, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occupation_title = df['final_title_post_processed']\n",
    "occupation_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e316fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = main_v3(occupation_title)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ef2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b0754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('normalized_soc_cleanup.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a678e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet('normalized_soc_cleanup.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46db102",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.read_excel('normalized_soc_cleanup.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.normalized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c81d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "jt_list = []\n",
    "for result in results_df.normalized[:5]:\n",
    "    regex1 = r\"\"\"Keywords': '(.+)', 'Results'\"\"\"\n",
    "    jt = re.findall(regex1, result)\n",
    "    #jt_list.append(jt)\n",
    "    jt_list += jt\n",
    "print(jt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc011ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "detail_jt_list = []\n",
    "for results in results_df.normalized:\n",
    "    regex2 = r\"\"\"categoryName': '([A-Za-z ]+)', 'score'\"\"\"\n",
    "    jt_normalized = re.findall(regex2, str(results))\n",
    "    detail_jt_list.append(jt_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f4221",
   "metadata": {},
   "outputs": [],
   "source": [
    "detail_jt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5cccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "score_list = []\n",
    "for results in results_df.normalized:\n",
    "    regex3 = r\"\"\"categoryName': '([A-Za-z ]+)', score': '([0-9].[0-9]+)','id'\"\"\"\n",
    "    score = re.findall(regex3, str(results))\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized'] = detail_jt_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1fec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29cc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = df.explode('normalized')\n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3981ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df.to_excel('normalized_soc_cleanup_exploded.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a3d6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33977675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a640914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b91220f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d339198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82102741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225cbef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09da9bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cadf134a",
   "metadata": {},
   "source": [
    "# Option 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217beae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = main_v3(occupation_title)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef12966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized'] = responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d67f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['normalized']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310431c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 1\n",
    "\n",
    "for normalized in df.normalized:\n",
    "    output = [result[\"Keywords\"]] \n",
    "    for result in results:   \n",
    "        print(result['categoryName'])\n",
    "        print(result['score'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01664511",
   "metadata": {},
   "outputs": [],
   "source": [
    "#option 2\n",
    "\n",
    "import csv\n",
    "\n",
    "results = df['normalized']\n",
    "\n",
    "with open(\"normalized_job_title.csv\", \"w\", encoding=\"utf-8\") as skill_fd:    \n",
    "    skill_fd.write(\"\\ufeff\")\n",
    "    skill_csv = csv.writer(skill_fd)\n",
    "    skill_csv.writerow([\"source\", \"normalised_title\", \"score\"])\n",
    "    for result in results:\n",
    "        output = [result[\"Keywords\"]]  \n",
    "        for skill in result[\"Results\"]: \n",
    "            output.append(skill[\"categoryName\"])   \n",
    "            output.append(skill[\"score\"])           \n",
    "        skill_csv.writerow(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('normalized_job_title.csv')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909b5e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44065c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalized'] = normalized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef62267",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c39a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df = df.explode('normalized')\n",
    "exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aadd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df.to_excel('normalized_soc_cleanup_exploded.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6837fb",
   "metadata": {},
   "source": [
    "# 02/29/2023 Ignore This Section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f471b",
   "metadata": {},
   "source": [
    "初期に抽出できなかった（トップ５マッチがなかった）ジョブタイトルをノーマライズ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5696f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a94b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('soc_normalized_titles_matches_02092023.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6720cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "tokenized_sents = []\n",
    "for job_title in df.Column1:\n",
    "    doc = nlp(job_title)\n",
    "    #tokenized_sents = []\n",
    "    sents = []\n",
    "    for sent in doc.sents:\n",
    "        sents.append(sent.text)\n",
    "        tokens = [i.text for i in sent]\n",
    "        tokenized_sents.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad429595",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a9ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# to select an aws profile if necessary\n",
    "profile_name = \"\"\n",
    "boto3.setup_default_session(profile_name=profile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "#endpoint3から拡張\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "region = \"ca-central-1\"\n",
    "vectorizer_name = \"vectorizer-cpu-2\"\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region)\n",
    "\n",
    "def vectorize_remote(\n",
    "        sents: List[List[str]],\n",
    "        offsets: List[List[List[int]]]) -> List[List[List[float]]]:\n",
    "    data = {\"sents\": sents, \"offsets\": offsets}\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=vectorizer_name,\n",
    "        Body=bytes(json.dumps(data), encoding=\"utf-8\"),\n",
    "        ContentType='application/json'\n",
    "\n",
    "    )\n",
    "    output = response['Body'].read().decode('utf-8')\n",
    "    output = json.loads(json.loads(output)[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f3247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[\n",
    "    [0, 24], # entire sentence --> vector\n",
    "    [15, 18], # SKILL   --> vector\n",
    "    [4, 5],  # noun --> vector\n",
    "    [10, 11] # verb --> vector\n",
    "    [20, 26] # SKILL --> vector\n",
    "\n",
    "]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3539731",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [[[0, len(sent)]] for sent in tokenized_sents]\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89907a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorize_remote(\n",
    "    tokenized_sents,\n",
    "    offsets\n",
    ")\n",
    "\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df641c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_faiss_name = \"semantic-search-cpu-2\"\n",
    "\n",
    "def get_matches(vectors: List[List[List[float]]]) \\\n",
    "        -> List[List[List[float]]]:\n",
    "    \"\"\"Get semantic search results either from sagemaker.\n",
    "\n",
    "    Args:\n",
    "        chunks List[str]: a list of chunk strings\n",
    "\n",
    "    Returns:\n",
    "        results Dict[str, List[List[List[int, float]]]]: a dictionary\n",
    "            where the keys are input sentences and the values are arrays of\n",
    "            search results. For each sentence, an array of 5 results is\n",
    "            returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sagemaker_runtime = boto3.client(\"sagemaker-runtime\",\n",
    "                                            region_name=region)\n",
    "        data = {\n",
    "            \"vectors\": vectors,\n",
    "            \"k\": 5\n",
    "        }\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=sagemaker_faiss_name,\n",
    "            Body=bytes(json.dumps(data), 'utf-8'),\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        raw_result: str = response['Body'].read().decode('utf-8')\n",
    "        results: List[List[List[int, float]]] = json.loads(raw_result)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = get_matches(vectors)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a86f0",
   "metadata": {},
   "source": [
    "# 02/09/2023 - No2 Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fad2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('soc_normalized_titles_matches_02092023.xlsx')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff939712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "job_title_list = []\n",
    "for job_title in df.Column1:\n",
    "    doc = nlp(job_title)\n",
    "    job_title_list.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cd264b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032cfa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users\\KeikoGolden/ComputationalLiguistics/Annotaion/bn_nb_s/PythonTocheckModel/soc_cleanup.xlsx\"\n",
    "df1 = pd.read_excel(file_path)\n",
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163604a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option 1\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "input_job_title_list = []\n",
    "for jt in df1.final_title_post_processed:\n",
    "    doc1 = nlp(str(jt))\n",
    "    input_job_title_list.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f127906",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_job_title_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fa1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2 - using df1 row - Do Not Use This\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "input_row_list = []\n",
    "for row in df1.iterrows():\n",
    "    doc1 = nlp(str(row))\n",
    "    input_row_list.append(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6443ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option1 -  Prints out blank cells if there is no match.\n",
    "normalized = []\n",
    "score = []\n",
    "original = []\n",
    "for x in job_title_list:\n",
    "    for y in input_job_title_list:\n",
    "        matches = x.similarity(y)\n",
    "        if matches > 0.75:\n",
    "            original.append(y)\n",
    "            normalized.append(x)\n",
    "            score.append(matches)\n",
    "        if not matches:\n",
    "            original.append(y)\n",
    "            normalized.append(\" \")\n",
    "            score.append(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd97cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb9caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option2 - only the matched title will output/\n",
    "normalized = []\n",
    "score = []\n",
    "original = []\n",
    "for x in job_title_list:\n",
    "    for y in input_job_title_list:\n",
    "        matches = x.similarity(y)\n",
    "        if matches > 0.75:\n",
    "            original.append(y)\n",
    "            normalized.append(x)\n",
    "            score.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff71bd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "original[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde8c071",
   "metadata": {},
   "outputs": [],
   "source": [
    "score[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fe642",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame({'minor_title': original, 'normalized_title': normalized, 'score': score})\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0cdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('left_over_jt_normalized_by_spacy.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel('left_over_jt_normalized_by_spacy_with_blank_cells.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68447818",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.minor_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0059df2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in job_title_list:\n",
    "    for y in input_job_title_list:\n",
    "        matches = x.similarity(y)\n",
    "        if matches > 0.75:\n",
    "            print(y, '| ', x, '| ', matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818fb6",
   "metadata": {},
   "source": [
    "# 02/11/2023 - SkyHive vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5061d5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_titles = df1.final_title_post_processed.to_csv(\"final_title_post_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa7e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"final_title_post_processed.csv\", 'r') as f:\n",
    "    sample_desc = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5971f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffc7420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc = nlp(sample_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad7da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents = []\n",
    "sents = []\n",
    "for sent in doc.sents:\n",
    "    sents.append(sent.text)\n",
    "    tokens = [i.text for i in sent]\n",
    "    tokenized_sents.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4eeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4435d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from typing import *\n",
    "\n",
    "region = \"ca-central-1\"\n",
    "vectorizer_name = \"vectorizer-cpu-2\"\n",
    "sagemaker_runtime = boto3.client(\"sagemaker-runtime\", region)\n",
    "\n",
    "def vectorize_remote(\n",
    "        sents: List[List[str]],\n",
    "        offsets: List[List[List[int]]]) -> List[List[List[float]]]:\n",
    "    data = {\"sents\": sents, \"offsets\": offsets}\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=vectorizer_name,\n",
    "        Body=bytes(json.dumps(data), encoding=\"utf-8\"),\n",
    "        ContentType='application/json'\n",
    "\n",
    "    )\n",
    "    output = response['Body'].read().decode('utf-8')\n",
    "    output = json.loads(json.loads(output)[0])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be97bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "offsets = [[[0, len(sent)]] for sent in tokenized_sents]\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adf4337",
   "metadata": {},
   "outputs": [],
   "source": [
    "#offsets = [[[0, len(i) + 2]] for i in tokenized_sents]\n",
    "#offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f09ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorize_remote(\n",
    "    tokenized_sents,\n",
    "    offsets\n",
    ")\n",
    "\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b7aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_faiss_name = \"semantic-search-cpu-2\"\n",
    "\n",
    "def get_matches(vectors: List[List[List[float]]]) \\\n",
    "        -> List[List[List[float]]]:\n",
    "    \"\"\"Get semantic search results either from sagemaker.\n",
    "\n",
    "    Args:\n",
    "        chunks List[str]: a list of chunk strings\n",
    "\n",
    "    Returns:\n",
    "        results Dict[str, List[List[List[int, float]]]]: a dictionary\n",
    "            where the keys are input sentences and the values are arrays of\n",
    "            search results. For each sentence, an array of 5 results is\n",
    "            returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sagemaker_runtime = boto3.client(\"sagemaker-runtime\",\n",
    "                                            region_name=region)\n",
    "        data = {\n",
    "            \"vectors\": vectors,\n",
    "            \"k\": 5\n",
    "        }\n",
    "        response = sagemaker_runtime.invoke_endpoint(\n",
    "            EndpointName=sagemaker_faiss_name,\n",
    "            Body=bytes(json.dumps(data), 'utf-8'),\n",
    "            ContentType='application/json'\n",
    "        )\n",
    "        raw_result: str = response['Body'].read().decode('utf-8')\n",
    "        results: List[List[List[int, float]]] = json.loads(raw_result)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522bf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = get_matches(vectors)\n",
    "\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebaf568",
   "metadata": {},
   "source": [
    "# 02/11/2023 - No2 Difflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2de2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:/Users\\KeikoGolden/ComputationalLiguistics/Annotaion/bn_nb_s/PythonTocheckModel/soc_cleanup.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d23ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(file_path)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e454a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_excel('soc_normalized_titles_matches_02092023.xlsx')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212dc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option1 -  Prints out blank cells if there is no match.\n",
    "\n",
    "import difflib\n",
    "\n",
    "normalized = []\n",
    "score = []\n",
    "original = []\n",
    "for x in str(df4.Column1):\n",
    "    for y in str(df.final_title_post_processed):\n",
    "        matches = difflib.get_close_matches(y, x, n=5, cutoff=0.75)\n",
    "        if matches:\n",
    "            original.append(y)\n",
    "            normalized.append(x)\n",
    "            score.append(matches)\n",
    "        if not matches:\n",
    "            original.append(y)\n",
    "            normalized.append(\" \")\n",
    "            score.append(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6885d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset = ['occupation_title_working']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e47e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.dropna(subset=['Column1']).copy()\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf50e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca67537a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Option2 - only the matched title will output/\n",
    "import difflib\n",
    "\n",
    "normalized = []\n",
    "score = []\n",
    "original = []\n",
    "\n",
    "for job_title in df['occupation_title_working']:\n",
    "    matches = difflib.get_close_matches(job_title, df4['Column1'].tolist(), n=5, cutoff=0.65)\n",
    "    if matches:\n",
    "        original.append(job_title)\n",
    "        normalized.append(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098fc60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab38a0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1 = pd.DataFrame({'minor_title': original, 'normalized_title': normalized})\n",
    "results_df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f754c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1 = results_df1.explode('normalized_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998fdf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df1.to_excel('difflib_normalized.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d8e94b",
   "metadata": {},
   "source": [
    "# 02/11/2023 Transformer Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914db84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3610a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a043b28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_minor_job_title = model.encode(df.final_title_post_processed.tolist())\n",
    "sentence_embeddings_job_title = model.encode(df4.Column1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_minor_job_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_job_title.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f27b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "minor_title = []\n",
    "normlised_title = []\n",
    "sim_score = []\n",
    "\n",
    "for i, job_title in enumerate(sentence_embeddings_job_title):\n",
    "    for j, title in enumerate(sentence_embeddings_minor_job_title):\n",
    "        score = cosine_similarity([job_title],[title])\n",
    "        if score > 0.80:\n",
    "            minor_title.append(df.final_title_post_processed.iloc[j])\n",
    "            normlised_title.append(df4.Column1.iloc[i])\n",
    "            sim_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72a27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_title[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(minor_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dbe2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "minor_title[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a556fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "normlised_title[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9093a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df_75 = pd.DataFrame({'minor_title': minor_title, 'normalized_title': normlised_title, 'score': sim_score})\n",
    "bert_df_75.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df_80 = pd.DataFrame({'minor_title': minor_title, 'normalized_title': normlised_title, 'score': sim_score})\n",
    "bert_df_80.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f2ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df_75.to_excel('BERT_75.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_df_80.to_excel('BERT_80.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41c766f",
   "metadata": {},
   "source": [
    "# 02/12/2023 - Using Original Detailed Title (occupation_title) with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada6ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_excel('soc_aligned.xlsx')\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de69b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize column names\n",
    "df5 = df5.rename(columns={ i: \"_\".join(i.lower().split(\"-\") ) for i in df5.columns })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac577b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355842ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_minor_job_title1 = model.encode(df5.occupation_title.tolist())\n",
    "sentence_embeddings_job_title1 = model.encode(df4.Column1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f937133",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "minor_title = []\n",
    "normlised_title = []\n",
    "sim_score = []\n",
    "\n",
    "for i, job_title in enumerate(sentence_embeddings_job_title1):\n",
    "    for j, title in enumerate(sentence_embeddings_minor_job_title1):\n",
    "        score = cosine_similarity([job_title],[title])\n",
    "        if score > 0.75:\n",
    "            minor_title.append(df5.occupation_title.iloc[j])\n",
    "            normlised_title.append(df4.Column1.iloc[i])\n",
    "            sim_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb84595",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_detailed_title_df_75 = pd.DataFrame({'occupation_title': minor_title, 'normalized_title': normlised_title, 'score': sim_score})\n",
    "bert_detailed_title_df_75.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c98e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(x):\n",
    "    res = str(x)[2:-2]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07167e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_detailed_title_df_75['score'] = bert_detailed_title_df_75.score.apply(remove_brackets).copy()\n",
    "bert_detailed_title_df_75['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_detailed_title_df_75.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_detailed_title_df_75.to_excel('bert_detailed_title75.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057603fb",
   "metadata": {},
   "source": [
    "# 02/16/2023 - Remaining 300+ skill extraction by BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e11175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4189649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd9212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaing_jt_df = pd.read_excel('normalized_titles_unresolved_feb15.xlsx')\n",
    "remaing_jt_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1548f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_jt_df = pd.read_excel('soc_cleanup.xlsx')\n",
    "detailed_jt_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f825eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_detialed_jt = model.encode(detailed_jt_df.final_title_post_processed.tolist())\n",
    "vector_ramaining_jt = model.encode(remaing_jt_df.normalized_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "detailed_title = []\n",
    "normlised_title = []\n",
    "sim_score = []\n",
    "\n",
    "for i, job_title in enumerate(vector_ramaining_jt):\n",
    "    for j, title in enumerate(vector_detialed_jt):\n",
    "        score = cosine_similarity([job_title],[title])\n",
    "        if score > 0.75:\n",
    "            detailed_title.append(detailed_jt_df.final_title_post_processed.iloc[j])\n",
    "            normlised_title.append(remaing_jt_df.normalized_title.iloc[i])\n",
    "            sim_score.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b430b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_300_normalized = pd.DataFrame({'detailed_title': detailed_title, 'normalized_title': normlised_title, 'score': sim_score})\n",
    "remaining_300_normalized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_brackets(x):\n",
    "    res = str(x)[2:-2]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b137f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_300_normalized['score'] = remaining_300_normalized.score.apply(remove_brackets).copy()\n",
    "remaining_300_normalized['score'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6e1f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_300_normalized.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_300_normalized.normalized_title.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0caf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remaining_300_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2819d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_300_normalized.to_excel('remaining_300_soc_normalized1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81dfc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = remaining_300_normalized.normalized_title.unique()\n",
    "len(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder = []\n",
    "for row in remaing_jt_df.normalized_title.tolist():\n",
    "    if row not in unique_values:\n",
    "        remainder.append(row)\n",
    "        #print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748f426",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efb80b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_df = pd.DataFrame({'remainder':remainder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "remainder_df.to_excel('remainder.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66da3d09",
   "metadata": {},
   "source": [
    "### ここから下は無視してオーケー。SkyHiveのパイプラインよりBERTの方が優れていることをアビゲルに証明するために同じデータでアウトプット。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45575032",
   "metadata": {},
   "source": [
    "#### オプション１"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1906b563",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_v3(skill_list, k=5):\n",
    "    response = requests.post(\n",
    "    url = 'https://testazure-ml-api.skyhive.io/job-title-normalization/titles_v3',\n",
    "    json = {\"titles\": skill_list, \"k\": k}\n",
    ")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def main_v3(skills: List[str]):\n",
    "    responses = []\n",
    "\n",
    "    for skill in tqdm(skills):\n",
    "        try:\n",
    "            response = normalize_v3([skill])\n",
    "        except:\n",
    "            response = None\n",
    "        responses.append(response)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b858ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "remaing_jt_df = pd.read_excel('normalized_titles_unresolved_feb15.xlsx')\n",
    "remaing_jt_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72aea5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_title = remaing_jt_df['normalized_title']\n",
    "occupation_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = main_v3(occupation_title)\n",
    "responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576e275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###WIP\n",
    "keywords_list = []\n",
    "new_normalized = []\n",
    "score = []\n",
    "\n",
    "for response in responses:\n",
    "    for i, keywords in enumerate(response):\n",
    "        for job_title in keywords[\"Results\"]: \n",
    "            new_normalized.append(job_title['categoryName']) \n",
    "            score.append(job_title[\"score\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9aaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_list = []\n",
    "new_normalized = []\n",
    "score = []\n",
    "\n",
    "for response in responses:\n",
    "    for keywords in response:\n",
    "        for job_title in keywords[\"Results\"]: \n",
    "            new_normalized.append(job_title['categoryName']) \n",
    "            score.append(job_title[\"score\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efa292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db63ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d2ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d449a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized_df['new_normalized_expanded'] = new_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2485e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized_df['score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0233770",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42a760",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_normalized_df.to_excel('skill_normalization_for_occupation_annotation.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf88066",
   "metadata": {},
   "source": [
    "### オプション２"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db01adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import vector_searc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99446770",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VectorSearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc85b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
